import custom_generator as generator
import bbox_utils as utils
import data_preparation_fishes as prep
from keras.models import Model
from keras.layers import Dropout, Flatten, Dense, MaxPooling2D, BatchNormalization
from keras import applications, optimizers
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
import keras.backend as K
import numpy as np
import pandas as pd
import os
from PIL import Image
import json
import shutil
import random
from keras.preprocessing import image
import re

train_path = 'C:/Projects/DeepLearning/Code_base/text_extractor/train'
test_path  = 'C:/Projects/DeepLearning/Code_base/text_extractor/test'
boxs_path ='C:/Projects/DeepLearning/Code_base/text_extractor/bounding_boxes/emailid.json'

img_width, img_height = 224, 224
epochs = 10
batch_size = 20

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)
    
def get_file_sizes(directory):
    file2sizes = {}
    for fname in os.listdir(directory):
     tmp = os.path.join(directory, fname)
     file2sizes[fname] = Image.open(tmp).size
    return file2sizes  

def get_bounding_boxes(bbox_directory):                
    null_largest = {'width':0, 'height': 0, 'x': 0, 'y': 0}
    file2boxes = {}
    fp = open(bbox_directory) 
    bxs = json.load(fp)
    for item in bxs:            
        fname = item['filename'].split('/')[-1]
        if len(item['annotations'])>0:
                largest = sorted(item['annotations'], key=lambda x: x['height']*x['width'])[-1]
                largest.pop('class')
        else:
            largest = null_largest
        file2boxes[fname] = largest
    return file2boxes    

def convert_bb(box, from_size, desired_size):
        item = box.copy()
        conv_x = (float(desired_size[0]) / float(from_size[0]))
        conv_y = (float(desired_size[1]) / float(from_size[1]))
        item['height'] = item['height']*conv_y
        item['width'] = item['width']*conv_x
        item['x'] = max(item['x']*conv_x, 0)
        item['y'] = max(item['y']*conv_y, 0)
        return item

def adjust_bounding_boxes(file2boxes, file2sizes, desired_size):
    f2b = file2boxes.copy()
    for file, box in f2b.items():
        tmp = convert_bb(box, file2sizes[file], desired_size)
        f2b[file] = [tmp['x'], tmp['y'], tmp['height'], tmp['width']]
    return f2b 


def preapare_full_dataset_for_flow(train_dir_original, test_dir_original, target_base_dir, val_percent=0.2):
    train_dir = os.path.join(target_base_dir, 'train')
    validation_dir = os.path.join(target_base_dir, 'validation')
    test_dir = os.path.join(target_base_dir, 'test')

    if os.path.exists(target_base_dir):
        print('required directory structure already exists. learning continues with existing data')
    else:          
        os.mkdir(target_base_dir)
        os.mkdir(train_dir)
        os.mkdir(validation_dir)
        os.mkdir(test_dir)
               
        shutil.move(test_dir_original, test_dir)
        print('moving of test data to target test directory finished')
        
        files = os.listdir(train_dir_original)
        train_files = [os.path.join(train_dir_original, f) for f in files]
        random.shuffle(train_files)    
        n = int(len(train_files) * val_percent)
        val = train_files[:n]
        train = train_files[n:]  

        for t in train:
             shutil.copy2(t, train_dir)
        for v in val:
             shutil.copy2(v, validation_dir)
        print('moving of input data to train and validation folders finished')

    nb_train_samples = 0  
    nb_validation_samples = 0
    
    nb_train_samples = len(os.listdir(train_dir))
    print('total training images:', nb_train_samples)
    
    nb_validation_samples = len(os.listdir(validation_dir))
    print('total validation images:', nb_validation_samples)    

    nb_test_samples = len(os.listdir(test_dir+'/test'))
    print('total test images:', nb_test_samples )
    
    
    return train_dir, validation_dir, test_dir, nb_train_samples, nb_validation_samples, nb_test_samples

    
file2sizes = get_file_sizes(train_path)
file2boxes = get_bounding_boxes(boxs_path)
desired_size = (img_width, img_width)
file2boxes = adjust_bounding_boxes(file2boxes, file2sizes, desired_size)

train_dir, validation_dir, test_dir, nb_train_samples, nb_validation_samples,nb_test_samples = \
                    preapare_full_dataset_for_flow(
                            train_dir_original = train_path, 
                            test_dir_original = test_path,
                            target_base_dir = 'C:/Projects/DeepLearning/Code_base/text_extractor/target1')

    
base_model = applications.VGG16(include_top=False, weights='imagenet', 
                           input_shape=(img_width, img_height, 3))

p = 0.2
x = base_model.output
x = MaxPooling2D()(x)
x = BatchNormalization(axis=1)(x)
x = Dropout(p/4)(x)
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)
x = Dropout(p/2)(x)
x_bb = Dense(4, name='bb')(x)
x_class = Dense(8, activation='softmax', name='class')(x)

for layer in base_model.layers:
    layer.trainable=False    
model = Model(inputs=base_model.input, outputs=[x_bb])
print(model.summary())

model.compile(optimizers.Adam(lr=0.001), 
              loss=['mse'], 
              metrics=['accuracy'],
              loss_weights=[.001])


#####################################################################################

## would work for some structures where you take in a map of the data and sort by filenames
def sort_as_filenames(data, filenames):
    output = []
    for fname in filenames:
        output.append(data[fname])
    return output

def array_to_img(x, dim_ordering='tf', scale=True):
    from PIL import Image
    if dim_ordering == 'th':
        x = x.transpose(1, 2, 0)
    if scale:
        x += max(-np.min(x), 0)
        x_max = np.max(x)
        if x_max != 0:
            x /= x_max
        x *= 255
    if x.shape[2] == 3:
        # RGB
        return Image.fromarray(x.astype('uint8'), 'RGB')
    elif x.shape[2] == 1:
        # grayscale
        return Image.fromarray(x[:, :, 0].astype('uint8'), 'L')
    else:
        raise Exception('Unsupported channel number: ', x.shape[2])


def img_to_array(img, dim_ordering='tf'):
    if dim_ordering not in ['th', 'tf']:
        raise Exception('Unknown dim_ordering: ', dim_ordering)
    # image has dim_ordering (height, width, channel)
    x = np.asarray(img, dtype='float32')
    if len(x.shape) == 3:
        if dim_ordering == 'th':
            x = x.transpose(2, 0, 1)
    elif len(x.shape) == 2:
        if dim_ordering == 'th':
            x = x.reshape((1, x.shape[0], x.shape[1]))
        else:
            x = x.reshape((x.shape[0], x.shape[1], 1))
    else:
        raise Exception('Unsupported image shape: ', x.shape)
    return x


def load_img(path, grayscale=False, target_size=None):
    '''Load an image into PIL format.
    # Arguments
        path: path to image file
        grayscale: boolean
        target_size: None (default to original size)
            or (img_height, img_width)
    '''
    from PIL import Image
    img = Image.open(path)
    if grayscale:
        img = img.convert('L')
    else:  # Ensure 3 channel even when loaded image is grayscale
        img = img.convert('RGB')
    if target_size:
        img = img.resize((target_size[1], target_size[0]))
    return img


def list_pictures(directory, ext='jpg|jpeg|bmp|png'):
    return [os.path.join(directory, f) for f in sorted(os.listdir(directory))
            if os.path.isfile(os.path.join(directory, f)) and re.match('([\w]+\.(?:' + ext + '))', f)]

class DirectoryIterator(image.Iterator):
    
    def __init__(self, directory, target_size=(224, 224), color_mode='rgb',
                 dim_ordering='tf',
                 classes=None, class_mode='sparse',
                 batch_size=32, shuffle=True, seed=None, map_extras=None):
        self.directory = directory
        self.target_size = tuple(target_size)
        self.map_extras = map_extras

        if color_mode not in {'rgb', 'grayscale'}:
            raise ValueError('Invalid color mode:', color_mode,
                             '; expected "rgb" or "grayscale".')
        self.color_mode = color_mode
        self.dim_ordering = dim_ordering
        if self.color_mode == 'rgb':
            if self.dim_ordering == 'tf':
                self.image_shape = self.target_size + (3,)
            else:
                self.image_shape = (3,) + self.target_size
        else:
            if self.dim_ordering == 'tf':
                self.image_shape = self.target_size + (1,)
            else:
                self.image_shape = (1,) + self.target_size
        self.classes = classes
        if class_mode not in {'categorical', 'binary', 'sparse', None}:
            raise ValueError('Invalid class_mode:', class_mode,
                             '; expected one of "categorical", '
                             '"binary", "sparse", or None.')
        self.class_mode = class_mode

        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp'}

        # first, count the number of samples and classes
        self.nb_sample = 0

        if not classes:
            classes = []
            for subdir in sorted(os.listdir(directory)):
                if os.path.isdir(os.path.join(directory, subdir)):
                    classes.append(subdir)
        self.nb_class = len(classes)
        self.class_indices = dict(zip(classes, range(len(classes))))
        #print(classes)
        #print(self.class_indices)

        for subdir in classes:
            subpath = os.path.join(directory, subdir)
            for fname in sorted(os.listdir(subpath)):
                is_valid = False
                for extension in white_list_formats:
                    if fname.lower().endswith('.' + extension):
                        is_valid = True
                        break
                if is_valid:
                    self.nb_sample += 1
        self.nb_sample = 1            
        print('Found %d images belonging to %d classes.' % (self.nb_sample, self.nb_class))

        # second, build an index of the images in the different class subfolders
        self.filenames = []
        self.classes = np.zeros((self.nb_sample,), dtype='int32')
        i = 0
        for subdir in classes:
            subpath = os.path.join(directory, subdir)
            for fname in sorted(os.listdir(subpath)):
                is_valid = False
                for extension in white_list_formats:
                    if fname.lower().endswith('.' + extension):
                        is_valid = True
                        break
                if is_valid:
                    self.classes[i] = self.class_indices[subdir]
                    self.filenames.append(os.path.join(subdir, fname))
                    i += 1
        for fname in  sorted(os.listdir(directory)):
            self.filenames.append(directory, fname)
        super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)
    

    
    def _get_batches_of_transformed_samples(self, index_array):
        #print(index_array)
        labels = []
        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype='float32')

        grayscale = self.color_mode == 'grayscale'
        
        if self.map_extras:
            boxes = np.zeros((len(batch_x), 4), dtype='float32')
        for i, j in enumerate(index_array):
            fname = self.filenames[j]
            img = load_img(os.path.join(self.directory, fname), grayscale=grayscale, target_size=self.target_size)
            x = img_to_array(img, dim_ordering=self.dim_ordering)
            batch_x[i] = x
    
            if self.map_extras:
                boxes[i] = self.map_extras.get(fname.split('\\')[-1])
       
        if self.class_mode == 'sparse':
            batch_y = self.classes[index_array]
        elif self.class_mode == 'binary':
            batch_y = self.classes[index_array].astype('float32')
        elif self.class_mode == 'categorical':
            batch_y = np.zeros((len(batch_x), self.nb_class), dtype='float32')
            for i, label in enumerate(self.classes[index_array]):
                batch_y[i, label] = 1.
        else:
            return batch_x
        
        if self.map_extras:
            return batch_x, [boxes, batch_y]
        else:
            return batch_x, batch_y

    def next(self):
        with self.lock:
            index_array = next(self.index_generator)
        return self._get_batches_of_transformed_samples(index_array)



#####################################################################################


train_generator = DirectoryIterator(train_dir,  target_size= (img_width, img_height), 
                                            batch_size=batch_size,  shuffle=True, map_extras=file2boxes)

validation_generator = image.DirectoryIterator(validation_dir,  target_size= (img_width, img_height), 
                                            batch_size=batch_size,  shuffle=True, map_extras=file2boxes)

save_weights = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=1, #nb_train_samples//batch_size,
    epochs=1, #epochs,
    validation_data=validation_generator,
    validation_steps=nb_validation_samples//batch_size,
    callbacks=[save_weights])

test_generator = generator.DirectoryIterator(test_dir,  target_size= (img_width, img_height), 
                                            class_mode = None, batch_size=batch_size,  shuffle=True)
preds = model.predict_generator(test_generator, nb_test_samples//batch_size)

class_probs = utils.do_clip(preds[1],0.82)
df = pd.DataFrame(class_probs, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])
img_ids = np.array([f.split('\\')[-1] for f in test_generator.filenames])
df.insert(0, 'image', img_ids)
df.to_csv('submission.csv', index=False)
